"""
dataset.py - è¡¨æƒ…è¯†åˆ«æ•°æ®é›†ç±»ï¼ˆé›†æˆæ•°æ®æ¸…æ´—åŠŸèƒ½ï¼‰
"""

import os
from PIL import Image
from torch.utils.data import Dataset
import torch
import numpy as np
import hashlib
from tqdm import tqdm
import shutil
from collections import defaultdict


class EmotionDataset(Dataset):
    """
    è¡¨æƒ…è¯†åˆ«æ•°æ®é›†ç±»ï¼ˆå¸¦è‡ªåŠ¨æ¸…æ´—åŠŸèƒ½ï¼‰
    """
    def __init__(self, root_dir, transform=None, auto_clean=False, clean_on_load=True):
        """
        åˆå§‹åŒ–æ•°æ®é›†

        Args:
            root_dir: æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„
            transform: å›¾åƒè½¬æ¢æ“ä½œ
            auto_clean: æ˜¯å¦åœ¨é¦–æ¬¡åŠ è½½æ—¶è‡ªåŠ¨æ¸…æ´—æ•°æ®
            clean_on_load: åŠ è½½æ—¶æ˜¯å¦éªŒè¯æ¯å¼ å›¾ç‰‡
        """
        self.root_dir = root_dir
        self.transform = transform
        self.clean_on_load = clean_on_load

        # å®šä¹‰5ä¸ªè¡¨æƒ…ç±»åˆ«
        self.classes = ['anger', 'fear', 'happy', 'sad', 'surprise']
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}

        # æ¸…æ´—ç»Ÿè®¡
        self.clean_stats = {
            'total_files': 0,
            'valid_files': 0,
            'corrupted': 0,
            'invalid_format': 0,
            'size_error': 0,
            'quality_error': 0
        }
        # å¦‚æœå¯ç”¨è‡ªåŠ¨æ¸…æ´—
        if auto_clean:
            print("\nğŸ§¹ è‡ªåŠ¨æ¸…æ´—æ¨¡å¼å·²å¯ç”¨")
            self._auto_clean_dataset()

        # åŠ è½½æ‰€æœ‰å›¾ç‰‡è·¯å¾„å’Œå¯¹åº”æ ‡ç­¾
        self.samples = []
        self._load_samples()

        print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼å…± {len(self.samples)} å¼ æœ‰æ•ˆå›¾ç‰‡")
        self._print_statistics()

        # å¦‚æœæœ‰æ¸…æ´—ç»Ÿè®¡ï¼Œæ˜¾ç¤º
        if self.clean_stats['total_files'] > 0:
            self._print_clean_stats()

    def _check_image_valid(self, img_path):
        """
        æ£€æŸ¥å›¾ç‰‡æ˜¯å¦æœ‰æ•ˆ

        Returns:
            (is_valid, error_type)
        """
        try:
            # å°è¯•æ‰“å¼€å›¾ç‰‡
            with Image.open(img_path) as img:
                # æ£€æŸ¥æ ¼å¼
                if img.format not in ['JPEG', 'PNG', 'BMP']:
                    return False, 'invalid_format'

                # æ£€æŸ¥å°ºå¯¸
                width, height = img.size
                if width < 32 or height < 32:
                    return False, 'size_error'

                if width > 2000 or height > 2000:
                    return False, 'size_error'

                # æ£€æŸ¥æ¨¡å¼
                if img.mode not in ['RGB', 'L', 'RGBA']:
                    return False, 'invalid_format'

                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                img_rgb = img.convert('RGB')
                img_array = np.array(img_rgb)

                # æ£€æŸ¥æ˜¯å¦å…¨é»‘æˆ–å…¨ç™½
                mean_val = img_array.mean()
                if mean_val < 5 or mean_val > 250:
                    return False, 'quality_error'

                # æ£€æŸ¥æ–¹å·®
                var = img_array.var()
                if var < 10:
                    return False, 'quality_error'

            return True, None

        except Exception as e:
            return False, 'corrupted'

    def _calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except:
            return None

    def _auto_clean_dataset(self):
        """è‡ªåŠ¨æ¸…æ´—æ•°æ®é›†"""
        print("\n" + "=" * 70)
        print("ğŸ” å¼€å§‹è‡ªåŠ¨æ¸…æ´—æ•°æ®é›†...")
        print("=" * 70)

        quarantine_dir = os.path.join(os.path.dirname(self.root_dir), 'quarantine')
        os.makedirs(quarantine_dir, exist_ok=True)

        # ç¬¬1æ­¥ï¼šæ£€æµ‹å¹¶ç§»é™¤æŸå/å¼‚å¸¸çš„å›¾ç‰‡
        print("\n1ï¸âƒ£  æ£€æµ‹æŸåå’Œå¼‚å¸¸å›¾ç‰‡...")

        problem_files = []
        hash_dict = defaultdict(list)

        for class_name in self.classes:
            class_dir = os.path.join(self.root_dir, class_name)
            if not os.path.exists(class_dir):
                continue

            files = [f for f in os.listdir(class_dir)
                    if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]

            print(f"\næ£€æŸ¥ {class_name} ç±»åˆ«...")

            for filename in tqdm(files, desc=f"  æ‰«æä¸­", ncols=80):
                file_path = os.path.join(class_dir, filename)
                self.clean_stats['total_files'] += 1

                # æ£€æŸ¥æœ‰æ•ˆæ€§
                is_valid, error_type = self._check_image_valid(file_path)

                if not is_valid:
                    problem_files.append((file_path, error_type, class_name, filename))
                    self.clean_stats[error_type] += 1
                else:
                    # æœ‰æ•ˆå›¾ç‰‡ï¼Œè®¡ç®—å“ˆå¸Œç”¨äºå»é‡
                    file_hash = self._calculate_file_hash(file_path)
                    if file_hash:
                        hash_dict[file_hash].append(file_path)

        # ç§»é™¤é—®é¢˜æ–‡ä»¶
        if problem_files:
            print(f"\nå‘ç° {len(problem_files)} ä¸ªé—®é¢˜æ–‡ä»¶ï¼Œæ­£åœ¨ç§»åŠ¨åˆ°éš”ç¦»åŒº...")

            for file_path, error_type, class_name, filename in tqdm(problem_files, desc="ç§»é™¤ä¸­", ncols=80):
                rel_path = os.path.relpath(file_path, self.root_dir)
                dst_path = os.path.join(quarantine_dir, error_type, rel_path)
                os.makedirs(os.path.dirname(dst_path), exist_ok=True)

                try:
                    shutil.move(file_path, dst_path)
                except:
                    pass

        # ç¬¬2æ­¥ï¼šæ£€æµ‹å¹¶ç§»é™¤é‡å¤å›¾ç‰‡
        print("\n2ï¸âƒ£  æ£€æµ‹é‡å¤å›¾ç‰‡...")

        duplicates = {k: v for k, v in hash_dict.items() if len(v) > 1}

        if duplicates:
            dup_count = sum(len(v) - 1 for v in duplicates.values())
            print(f"\nå‘ç° {len(duplicates)} ç»„é‡å¤ï¼ˆå…± {dup_count} ä¸ªé‡å¤æ–‡ä»¶ï¼‰")

            for hash_val, files in tqdm(duplicates.items(), desc="ç§»é™¤é‡å¤", ncols=80):
                # ä¿ç•™ç¬¬ä¸€ä¸ªï¼Œç§»é™¤å…¶ä½™
                for file_path in files[1:]:
                    rel_path = os.path.relpath(file_path, self.root_dir)
                    dst_path = os.path.join(quarantine_dir, 'duplicates', rel_path)
                    os.makedirs(os.path.dirname(dst_path), exist_ok=True)

                    try:
                        shutil.move(file_path, dst_path)
                    except:
                        pass
        else:
            print("âœ“ æœªå‘ç°é‡å¤å›¾ç‰‡")

        print("\n" + "=" * 70)
        print("âœ… è‡ªåŠ¨æ¸…æ´—å®Œæˆï¼")
        print("=" * 70)
        print(f"éš”ç¦»ç›®å½•: {quarantine_dir}")

    def _load_samples(self):
        """åŠ è½½æ‰€æœ‰å›¾ç‰‡è·¯å¾„å’Œæ ‡ç­¾ï¼ˆå¸¦éªŒè¯ï¼‰"""
        for class_name in self.classes:
            class_dir = os.path.join(self.root_dir, class_name)

            if not os.path.exists(class_dir):
                print(f"âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶å¤¹ {class_dir} ä¸å­˜åœ¨ï¼")
                continue

            # éå†è¯¥ç±»åˆ«æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
            files = [f for f in os.listdir(class_dir)
                    if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]

            for img_name in files:
                img_path = os.path.join(class_dir, img_name)

                # å¦‚æœå¯ç”¨äº†åŠ è½½æ—¶éªŒè¯
                if self.clean_on_load:
                    is_valid, error_type = self._check_image_valid(img_path)

                    if not is_valid:
                        # è®°å½•ç»Ÿè®¡ä½†ä¸æ·»åŠ åˆ°æ ·æœ¬ä¸­
                        if error_type:
                            self.clean_stats[error_type] = self.clean_stats.get(error_type, 0) + 1
                        continue

                label = self.class_to_idx[class_name]
                self.samples.append((img_path, label))
                self.clean_stats['valid_files'] += 1

    def _print_statistics(self):
        """æ‰“å°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        print("\nå„ç±»åˆ«å›¾ç‰‡æ•°é‡ï¼š")
        for class_name in self.classes:
            count = sum(1 for _, label in self.samples
                       if label == self.class_to_idx[class_name])
            print(f"  {class_name}: {count} å¼ ")

    def _print_clean_stats(self):
        """æ‰“å°æ¸…æ´—ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 70)
        print("ğŸ§¹ æ¸…æ´—ç»Ÿè®¡")
        print("=" * 70)

        if self.clean_stats['total_files'] > 0:
            print(f"æ€»æ‰«ææ–‡ä»¶: {self.clean_stats['total_files']}")
            print(f"æœ‰æ•ˆæ–‡ä»¶: {self.clean_stats['valid_files']}")

            problem_count = (self.clean_stats.get('corrupted', 0) +
                           self.clean_stats.get('invalid_format', 0) +
                           self.clean_stats.get('size_error', 0) +
                           self.clean_stats.get('quality_error', 0))

            if problem_count > 0:
                print(f"\né—®é¢˜æ–‡ä»¶: {problem_count}")
                if self.clean_stats.get('corrupted', 0) > 0:
                    print(f"  - æŸå: {self.clean_stats['corrupted']}")
                if self.clean_stats.get('invalid_format', 0) > 0:
                    print(f"  - æ ¼å¼é”™è¯¯: {self.clean_stats['invalid_format']}")
                if self.clean_stats.get('size_error', 0) > 0:
                    print(f"  - å°ºå¯¸é”™è¯¯: {self.clean_stats['size_error']}")
                if self.clean_stats.get('quality_error', 0) > 0:
                    print(f"  - è´¨é‡è¿‡ä½: {self.clean_stats['quality_error']}")
            else:
                print("âœ“ æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰æ•ˆ")

    def __len__(self):
        """è¿”å›æ•°æ®é›†å¤§å°"""
        return len(self.samples)

    def __getitem__(self, idx):
        """
        è·å–ä¸€ä¸ªæ ·æœ¬

        Args:
            idx: æ ·æœ¬ç´¢å¼•

        Returns:
            image: å¤„ç†åçš„å›¾åƒtensor
            label: æ ‡ç­¾
        """
        img_path, label = self.samples[idx]

        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºRGB
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"è¯»å–å›¾ç‰‡å¤±è´¥: {img_path}, é”™è¯¯: {e}")
            # å¦‚æœè¯»å–å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªé»‘è‰²å›¾ç‰‡
            image = Image.new('RGB', (48, 48), (0, 0, 0))

        # åº”ç”¨æ•°æ®è½¬æ¢
        if self.transform:
            image = self.transform(image)

        return image, label

    def get_class_name(self, idx):
        """æ ¹æ®ç´¢å¼•è·å–ç±»åˆ«åç§°"""
        return self.classes[idx]

    def get_class_distribution(self):
        """è·å–ç±»åˆ«åˆ†å¸ƒ"""
        distribution = {class_name: 0 for class_name in self.classes}

        for _, label in self.samples:
            class_name = self.classes[label]
            distribution[class_name] += 1

        return distribution

    @staticmethod
    def clean_directory(data_dir, move_to_quarantine=True, remove_duplicates=True):
        """
        é™æ€æ–¹æ³•ï¼šç‹¬ç«‹æ¸…æ´—æ•°æ®ç›®å½•

        Args:
            data_dir: æ•°æ®ç›®å½•
            move_to_quarantine: æ˜¯å¦ç§»åŠ¨åˆ°éš”ç¦»åŒº
            remove_duplicates: æ˜¯å¦ç§»é™¤é‡å¤

        Returns:
            æ¸…æ´—ç»Ÿè®¡å­—å…¸
        """
        print("\n" + "=" * 70)
        print("ğŸ§¹ ç‹¬ç«‹æ¸…æ´—æ¨¡å¼")
        print("=" * 70)
        print(f"æ•°æ®ç›®å½•: {data_dir}")

        # åˆ›å»ºä¸´æ—¶æ•°æ®é›†å¯¹è±¡è¿›è¡Œæ¸…æ´—
        temp_dataset = EmotionDataset.__new__(EmotionDataset)
        temp_dataset.root_dir = data_dir
        temp_dataset.classes = ['anger', 'fear', 'happy', 'sad', 'surprise']
        temp_dataset.clean_stats = {
            'total_files': 0,
            'valid_files': 0,
            'corrupted': 0,
            'invalid_format': 0,
            'size_error': 0,
            'quality_error': 0
        }

        # æ‰§è¡Œæ¸…æ´—
        temp_dataset._auto_clean_dataset()

        return temp_dataset.clean_stats


# ä¾¿æ·å‡½æ•°
def create_clean_dataset(root_dir, transform=None, auto_clean=True):
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºè‡ªåŠ¨æ¸…æ´—çš„æ•°æ®é›†

    Args:
        root_dir: æ•°æ®ç›®å½•
        transform: è½¬æ¢æ“ä½œ
        auto_clean: æ˜¯å¦è‡ªåŠ¨æ¸…æ´—

    Returns:
        EmotionDatasetå¯¹è±¡
    """
    return EmotionDataset(root_dir, transform=transform, auto_clean=auto_clean)


def quick_clean(data_dir):
    """
    ä¾¿æ·å‡½æ•°ï¼šå¿«é€Ÿæ¸…æ´—æ•°æ®ç›®å½•ï¼ˆä¸åˆ›å»ºæ•°æ®é›†ï¼‰

    Args:
        data_dir: æ•°æ®ç›®å½•

    Returns:
        æ¸…æ´—ç»Ÿè®¡
    """
    return EmotionDataset.clean_directory(data_dir)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    from torchvision import transforms

    print("\n" + "=" * 70)
    print("ğŸ§ª æ•°æ®é›†æµ‹è¯•")
    print("=" * 70)

    print("\né€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("  [1] åŠ è½½æ•°æ®é›†ï¼ˆä¸æ¸…æ´—ï¼‰")
    print("  [2] åŠ è½½æ•°æ®é›†ï¼ˆè‡ªåŠ¨æ¸…æ´—ï¼‰")
    print("  [3] ä»…æ¸…æ´—æ•°æ®ï¼ˆä¸åŠ è½½ï¼‰")

    choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()

    # å®šä¹‰ç®€å•çš„è½¬æ¢
    transform = transforms.Compose([
        transforms.Resize((48, 48)),
        transforms.ToTensor(),
    ])

    if choice == '1':
        # æ™®é€šåŠ è½½
        print("\næ™®é€šåŠ è½½æ¨¡å¼...")
        dataset = EmotionDataset(
            root_dir='../data/raw',
            transform=transform,
            auto_clean=False,
            clean_on_load=False
        )

    elif choice == '2':
        # è‡ªåŠ¨æ¸…æ´—åŠ è½½
        print("\nè‡ªåŠ¨æ¸…æ´—æ¨¡å¼...")
        dataset = EmotionDataset(
            root_dir='../data/raw',
            transform=transform,
            auto_clean=True,
            clean_on_load=True
        )

    elif choice == '3':
        # ä»…æ¸…æ´—
        print("\nä»…æ¸…æ´—æ¨¡å¼...")
        stats = quick_clean('../data/raw')

        print("\næ¸…æ´—å®Œæˆï¼ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"  {key}: {value}")

        exit(0)

    else:
        print("æ— æ•ˆé€‰æ‹©")
        exit(1)

    # æµ‹è¯•è·å–æ ·æœ¬
    if len(dataset) > 0:
        print(f"\næµ‹è¯•æ ·æœ¬ï¼š")
        image, label = dataset[0]
        print(f"  å›¾åƒå½¢çŠ¶: {image.shape}")
        print(f"  æ ‡ç­¾: {label} ({dataset.get_class_name(label)})")

        # æ˜¾ç¤ºç±»åˆ«åˆ†å¸ƒ
        print(f"\nç±»åˆ«åˆ†å¸ƒï¼š")
        distribution = dataset.get_class_distribution()
        for class_name, count in distribution.items():
            print(f"  {class_name}: {count} å¼ ")
    else:
        print("\nâš ï¸  æ•°æ®é›†ä¸ºç©ºï¼è¯·æ£€æŸ¥data/rawæ–‡ä»¶å¤¹ä¸­æ˜¯å¦æœ‰å›¾ç‰‡ã€‚")

    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)