"""
train_multiple.py - æ‰¹é‡è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶å¯¹æ¯”ç»“æœï¼ˆå¸¦æ¨¡å‹é€‰æ‹©å’Œè¿›åº¦å¯è§†åŒ–ï¼‰
"""

import torch
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from train import train_model
import time
import os
from datetime import datetime


def select_models():
    """
    äº¤äº’å¼é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹

    Returns:
        selected_configs: é€‰ä¸­çš„æ¨¡å‹é…ç½®åˆ—è¡¨
    """
    # æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®
    all_models = [
        {
            'id': 1,
            'name': 'ResNet18',
            'model_type': 'resnet18',
            'num_epochs': 20,
            'batch_size': 64,
            'learning_rate': 0.001,
            'description': 'æœ€æ¨è - å¹³è¡¡æ€§æœ€å¥½',
            'time_estimate': '20-30åˆ†é’Ÿ(GPU) / 2-3å°æ—¶(CPU)'
        },
        {
            'id': 2,
            'name': 'MobileNet',
            'model_type': 'mobilenet',
            'num_epochs': 20,
            'batch_size': 128,
            'learning_rate': 0.001,
            'description': 'æœ€å¿« - è½»é‡çº§æ¨¡å‹',
            'time_estimate': '15-20åˆ†é’Ÿ(GPU) / 1-2å°æ—¶(CPU)'
        },
        {
            'id': 3,
            'name': 'EfficientNet',
            'model_type': 'efficientnet',
            'num_epochs': 20,
            'batch_size': 64,
            'learning_rate': 0.001,
            'description': 'æœ€å…ˆè¿› - æœ€ä½³å¹³è¡¡',
            'time_estimate': '25-35åˆ†é’Ÿ(GPU) / 3-4å°æ—¶(CPU)'
        },
        {
            'id': 4,
            'name': 'ResNet34',
            'model_type': 'resnet34',
            'num_epochs': 20,
            'batch_size': 64,
            'learning_rate': 0.001,
            'description': 'æ›´æ·± - æ›´é«˜å‡†ç¡®ç‡',
            'time_estimate': '30-40åˆ†é’Ÿ(GPU) / 3-5å°æ—¶(CPU)'
        },
        {
            'id': 5,
            'name': 'ResNet50',
            'model_type': 'resnet50',
            'num_epochs': 20,
            'batch_size': 32,
            'learning_rate': 0.001,
            'description': 'æœ€å¼º - æœ€é«˜å‡†ç¡®ç‡',
            'time_estimate': '35-50åˆ†é’Ÿ(GPU) / 4-6å°æ—¶(CPU)'
        },
        {
            'id': 6,
            'name': 'VGG16',
            'model_type': 'vgg16',
            'num_epochs': 20,
            'batch_size': 32,
            'learning_rate': 0.001,
            'description': 'ç»å…¸ - CNNæ¶æ„',
            'time_estimate': '40-60åˆ†é’Ÿ(GPU) / 5-8å°æ—¶(CPU)'
        },
        {
            'id': 7,
            'name': 'Custom CNN',
            'model_type': 'cnn',
            'num_epochs': 30,
            'batch_size': 64,
            'learning_rate': 0.001,
            'description': 'è‡ªå®šä¹‰ - ä»é›¶è®­ç»ƒ',
            'time_estimate': '40-60åˆ†é’Ÿ(GPU) / 4-6å°æ—¶(CPU)'
        }
    ]

    print("\n" + "=" * 80)
    print("å¯ç”¨æ¨¡å‹åˆ—è¡¨")
    print("=" * 80)
    for model in all_models:
        print(f"  [{model['id']}] {model['name']:15s} - {model['description']}")
        print(f"      é¢„è®¡è®­ç»ƒæ—¶é—´: {model['time_estimate']}")
    print("=" * 80)

    print("\né€‰æ‹©æ¨¡å¼:")
    print("  [0] è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    print("  [1-7] è®­ç»ƒå•ä¸ªæ¨¡å‹")
    print("  è¾“å…¥å¤šä¸ªæ•°å­—ï¼ˆç”¨é€—å·æˆ–ç©ºæ ¼åˆ†éš”ï¼‰è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œä¾‹å¦‚: 1,2,3 æˆ– 1 2 3")

    while True:
        choice = input("\nè¯·è¾“å…¥ä½ çš„é€‰æ‹©: ").strip()

        if choice == '0':
            print("\nâœ… å·²é€‰æ‹©: è®­ç»ƒæ‰€æœ‰7ä¸ªæ¨¡å‹")
            return all_models

        # è§£æè¾“å…¥
        try:
            # æ”¯æŒé€—å·æˆ–ç©ºæ ¼åˆ†éš”
            if ',' in choice:
                selected_ids = [int(x.strip()) for x in choice.split(',')]
            else:
                selected_ids = [int(x.strip()) for x in choice.split()]

            # éªŒè¯IDæœ‰æ•ˆæ€§
            if all(1 <= id <= 7 for id in selected_ids):
                selected_models = [m for m in all_models if m['id'] in selected_ids]

                print(f"\nâœ… å·²é€‰æ‹© {len(selected_models)} ä¸ªæ¨¡å‹:")
                for model in selected_models:
                    print(f"  - {model['name']}")

                confirm = input("\nç¡®è®¤å¼€å§‹è®­ç»ƒ? (y/n): ").strip().lower()
                if confirm == 'y':
                    return selected_models
                else:
                    print("å·²å–æ¶ˆï¼Œè¯·é‡æ–°é€‰æ‹©")
            else:
                print("âŒ æ— æ•ˆè¾“å…¥ï¼è¯·è¾“å…¥1-7ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼è¯·è¾“å…¥æ•°å­—")


def print_progress_bar(current, total, bar_length=50):
    """
    æ‰“å°ASCIIè¿›åº¦æ¡

    Args:
        current: å½“å‰è¿›åº¦
        total: æ€»æ•°
        bar_length: è¿›åº¦æ¡é•¿åº¦
    """
    percent = current / total
    filled_length = int(bar_length * percent)
    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
    print(f"\ræ€»ä½“è¿›åº¦: [{bar}] {current}/{total} ({percent*100:.1f}%)", end='', flush=True)


def visualize_realtime_progress(results, current_model_name):
    """
    å®æ—¶å¯è§†åŒ–è®­ç»ƒè¿›åº¦

    Args:
        results: å½“å‰æ‰€æœ‰ç»“æœ
        current_model_name: å½“å‰æ­£åœ¨è®­ç»ƒçš„æ¨¡å‹åç§°
    """
    if not results:
        return

    # åªæ˜¾ç¤ºæˆåŠŸçš„ç»“æœ
    successful_results = [r for r in results if r.get('status') == 'Success']

    if not successful_results:
        return

    df = pd.DataFrame(successful_results)

    # åˆ›å»ºå®æ—¶è¿›åº¦å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # 1. å‡†ç¡®ç‡è¿›åº¦
    ax1 = axes[0]
    colors = ['green' if acc >= 80 else 'orange' if acc >= 70 else 'red'
              for acc in df['best_val_acc']]
    bars1 = ax1.barh(df['model'], df['best_val_acc'], color=colors, alpha=0.7)
    ax1.set_xlabel('Validation Accuracy (%)', fontsize=11, fontweight='bold')
    ax1.set_title('Current Training Progress - Accuracy', fontsize=12, fontweight='bold')
    ax1.grid(axis='x', alpha=0.3)

    for i, (bar, acc) in enumerate(zip(bars1, df['best_val_acc'])):
        ax1.text(acc + 1, bar.get_y() + bar.get_height()/2,
                f'{acc:.2f}%', va='center', fontsize=10)

    # 2. è®­ç»ƒæ—¶é—´
    ax2 = axes[1]
    bars2 = ax2.barh(df['model'], df['training_time_min'], color='steelblue', alpha=0.7)
    ax2.set_xlabel('Training Time (minutes)', fontsize=11, fontweight='bold')
    ax2.set_title('Training Time Comparison', fontsize=12, fontweight='bold')
    ax2.grid(axis='x', alpha=0.3)

    for i, (bar, time_min) in enumerate(zip(bars2, df['training_time_min'])):
        ax2.text(time_min + 1, bar.get_y() + bar.get_height()/2,
                f'{time_min:.1f}m', va='center', fontsize=10)

    plt.tight_layout()

    # ä¿å­˜å®æ—¶è¿›åº¦å›¾
    save_path = '../results/training_progress_realtime.png'
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()


def train_all_models(selected_models):
    """
    è®­ç»ƒé€‰ä¸­çš„æ¨¡å‹å¹¶ä¿å­˜å¯¹æ¯”ç»“æœ

    Args:
        selected_models: é€‰ä¸­çš„æ¨¡å‹é…ç½®åˆ—è¡¨
    """

    print("\n" + "=" * 80)
    print("æ‰¹é‡è®­ç»ƒæ¨¡å‹å¯¹æ¯”å®éªŒ")
    print("=" * 80)
    print(f"å°†è®­ç»ƒ {len(selected_models)} ä¸ªæ¨¡å‹:")
    for i, config in enumerate(selected_models, 1):
        print(f"  {i}. {config['name']:15s} - {config['description']}")
    print("=" * 80)

    # è®°å½•å¼€å§‹æ—¶é—´
    total_start_time = time.time()

    # å­˜å‚¨æ‰€æœ‰æ¨¡å‹çš„ç»“æœ
    results = []

    # å¼€å§‹è®­ç»ƒæ¯ä¸ªæ¨¡å‹
    for i, config in enumerate(selected_models, 1):
        print(f"\n\n{'='*80}")
        print(f"[{i}/{len(selected_models)}] å¼€å§‹è®­ç»ƒ: {config['name']}")
        print(f"é¢„è®¡æ—¶é—´: {config['time_estimate']}")
        print(f"{'='*80}\n")

        # æ›´æ–°æ€»ä½“è¿›åº¦æ¡
        print_progress_bar(i-1, len(selected_models))
        print()  # æ¢è¡Œ

        start_time = time.time()

        try:
            # è®­ç»ƒæ¨¡å‹
            model, history = train_model(
                model_type=config['model_type'],
                num_epochs=config['num_epochs'],
                batch_size=config['batch_size'],
                learning_rate=config['learning_rate'],
                device='auto'
            )

            training_time = time.time() - start_time

            # è®°å½•ç»“æœ
            result = {
                'model': config['name'],
                'model_type': config['model_type'],
                'epochs': config['num_epochs'],
                'batch_size': config['batch_size'],
                'best_train_acc': max(history['train_acc']),
                'best_val_acc': max(history['val_acc']),
                'final_train_acc': history['train_acc'][-1],
                'final_val_acc': history['val_acc'][-1],
                'final_train_loss': history['train_loss'][-1],
                'final_val_loss': history['val_loss'][-1],
                'training_time_min': training_time / 60,
                'training_time_sec': training_time,
                'status': 'Success',
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }

            results.append(result)

            print(f"\n{'='*80}")
            print(f"âœ… {config['name']} è®­ç»ƒå®Œæˆ!")
            print(f"{'='*80}")
            print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {result['best_val_acc']:.2f}%")
            print(f"   è®­ç»ƒæ—¶é—´: {result['training_time_min']:.2f} åˆ†é’Ÿ")
            print(f"   å®Œæˆæ—¶é—´: {result['timestamp']}")

            # ä¿å­˜ä¸­é—´ç»“æœ
            save_results_table(results)

            # å®æ—¶å¯è§†åŒ–è¿›åº¦
            visualize_realtime_progress(results, config['name'])

        except Exception as e:
            print(f"\nâŒ {config['name']} è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            result = {
                'model': config['name'],
                'model_type': config['model_type'],
                'status': f'Failed: {str(e)}',
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            results.append(result)

    # æ›´æ–°æœ€ç»ˆè¿›åº¦æ¡
    print_progress_bar(len(selected_models), len(selected_models))
    print("\n")

    # è®¡ç®—æ€»æ—¶é—´
    total_time = time.time() - total_start_time

    # è®­ç»ƒå®Œæˆï¼Œç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "=" * 80)
    print("æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("=" * 80)
    print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time/3600:.2f} å°æ—¶ ({total_time/60:.2f} åˆ†é’Ÿ)")

    generate_comparison_report(results)

    return results


def save_results_table(results):
    """ä¿å­˜ç»“æœè¡¨æ ¼"""
    df = pd.DataFrame(results)

    # ä¿å­˜ä¸ºCSV
    csv_path = '../results/models_comparison.csv'
    os.makedirs(os.path.dirname(csv_path), exist_ok=True)
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')

    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {csv_path}")


def generate_comparison_report(results):
    """ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Š"""

    # åªä¿ç•™æˆåŠŸçš„æ¨¡å‹
    successful_results = [r for r in results if r.get('status') == 'Success']

    if not successful_results:
        print("\nâš ï¸  æ²¡æœ‰æˆåŠŸè®­ç»ƒçš„æ¨¡å‹ï¼Œæ— æ³•ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š")
        return

    df = pd.DataFrame(successful_results)

    print("\n" + "=" * 80)
    print("ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("=" * 80)
    print(df[['model', 'best_val_acc', 'final_val_acc', 'training_time_min']].to_string(index=False))

    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_acc_model = df.loc[df['best_val_acc'].idxmax()]
    fastest_model = df.loc[df['training_time_min'].idxmin()]

    # è®¡ç®—æ•ˆç‡æœ€é«˜çš„æ¨¡å‹ï¼ˆå‡†ç¡®ç‡/æ—¶é—´ï¼‰
    df['efficiency'] = df['best_val_acc'] / df['training_time_min']
    most_efficient = df.loc[df['efficiency'].idxmax()]

    print("\n" + "=" * 80)
    print("ğŸ† å…³é”®æŒ‡æ ‡")
    print("=" * 80)
    print(f"ğŸ¥‡ æœ€é«˜å‡†ç¡®ç‡: {best_acc_model['model']} - {best_acc_model['best_val_acc']:.2f}%")
    print(f"âš¡ æœ€å¿«è®­ç»ƒ: {fastest_model['model']} - {fastest_model['training_time_min']:.2f} åˆ†é’Ÿ")
    print(f"ğŸ’¡ æœ€é«˜æ•ˆç‡: {most_efficient['model']} - {most_efficient['efficiency']:.2f} (å‡†ç¡®ç‡%/åˆ†é’Ÿ)")

    # ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨
    plot_comparison_charts(df)


def plot_comparison_charts(df):
    """ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨"""

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # è®¾ç½®é¢œè‰²æ–¹æ¡ˆ
    colors = plt.cm.Set3(range(len(df)))

    # 1. éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”
    ax1 = axes[0, 0]
    bars1 = ax1.bar(df['model'], df['best_val_acc'], color=colors, alpha=0.8, edgecolor='black')
    ax1.set_xlabel('Model', fontsize=12, fontweight='bold')
    ax1.set_ylabel('Best Validation Accuracy (%)', fontsize=12, fontweight='bold')
    ax1.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(axis='y', alpha=0.3)
    ax1.set_ylim([0, 100])

    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{height:.2f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')

    # 2. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    ax2 = axes[0, 1]
    bars2 = ax2.bar(df['model'], df['training_time_min'], color=colors, alpha=0.8, edgecolor='black')
    ax2.set_xlabel('Model', fontsize=12, fontweight='bold')
    ax2.set_ylabel('Training Time (minutes)', fontsize=12, fontweight='bold')
    ax2.set_title('Training Time Comparison', fontsize=14, fontweight='bold')
    ax2.tick_params(axis='x', rotation=45)
    ax2.grid(axis='y', alpha=0.3)

    for bar in bars2:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{height:.1f}m', ha='center', va='bottom', fontsize=10, fontweight='bold')

    # 3. æ•ˆç‡å¯¹æ¯” (å‡†ç¡®ç‡ / è®­ç»ƒæ—¶é—´)
    ax3 = axes[1, 0]
    efficiency = df['best_val_acc'] / df['training_time_min']
    bars3 = ax3.bar(df['model'], efficiency, color=colors, alpha=0.8, edgecolor='black')
    ax3.set_xlabel('Model', fontsize=12, fontweight='bold')
    ax3.set_ylabel('Efficiency (Acc% / min)', fontsize=12, fontweight='bold')
    ax3.set_title('Training Efficiency (Higher is Better)', fontsize=14, fontweight='bold')
    ax3.tick_params(axis='x', rotation=45)
    ax3.grid(axis='y', alpha=0.3)

    for bar in bars3:
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                f'{height:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')

    # 4. è®­ç»ƒæŸå¤± vs éªŒè¯æŸå¤±
    ax4 = axes[1, 1]
    x_pos = range(len(df))
    width = 0.35
    bars4a = ax4.bar([p - width/2 for p in x_pos], df['final_train_loss'],
                     width, label='Train Loss', color='lightblue', alpha=0.8, edgecolor='black')
    bars4b = ax4.bar([p + width/2 for p in x_pos], df['final_val_loss'],
                     width, label='Val Loss', color='lightcoral', alpha=0.8, edgecolor='black')
    ax4.set_xlabel('Model', fontsize=12, fontweight='bold')
    ax4.set_ylabel('Loss', fontsize=12, fontweight='bold')
    ax4.set_title('Final Loss Comparison', fontsize=14, fontweight='bold')
    ax4.set_xticks(x_pos)
    ax4.set_xticklabels(df['model'], rotation=45, ha='right')
    ax4.legend(fontsize=11)
    ax4.grid(axis='y', alpha=0.3)

    plt.tight_layout()

    save_path = '../results/models_comparison.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"\nğŸ“Š å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
    plt.close()


if __name__ == "__main__":
    print("\n" + "=" * 80)
    print("ğŸš€ æ¬¢è¿ä½¿ç”¨æ‰¹é‡è®­ç»ƒè„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰")
    print("=" * 80)
    print("\nåŠŸèƒ½ç‰¹ç‚¹:")
    print("  âœ… è‡ªç”±é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹")
    print("  âœ… å®æ—¶è¿›åº¦å¯è§†åŒ–")
    print("  âœ… è‡ªåŠ¨ä¿å­˜ä¸­é—´ç»“æœ")
    print("  âœ… è¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")

    # æ£€æµ‹è®¾å¤‡
    device = 'GPU' if torch.cuda.is_available() else 'CPU'
    print(f"\nå½“å‰è®¾å¤‡: {device}")

    if device == 'CPU':
        print("\nâš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°GPUï¼Œè®­ç»ƒé€Ÿåº¦ä¼šè¾ƒæ…¢")
        print("   å»ºè®®: å…ˆé€‰æ‹©1-2ä¸ªè½»é‡çº§æ¨¡å‹ï¼ˆå¦‚MobileNetï¼‰è¿›è¡Œæµ‹è¯•")

    # é€‰æ‹©æ¨¡å‹
    selected_models = select_models()

    # ç¡®è®¤å¼€å§‹
    print("\n" + "=" * 80)
    print("å‡†å¤‡å¼€å§‹è®­ç»ƒ...")
    print("=" * 80)
    input("\næŒ‰ Enter é”®å¼€å§‹è®­ç»ƒ...")

    # å¼€å§‹è®­ç»ƒ
    results = train_all_models(selected_models)

    print("\n" + "=" * 80)
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print("=" * 80)
    print("\næŸ¥çœ‹ç»“æœ:")
    print("  ğŸ“„ è¯¦ç»†æ•°æ®: results/models_comparison.csv")
    print("  ğŸ“Š å¯¹æ¯”å›¾è¡¨: results/models_comparison.png")
    print("  ğŸ“ˆ å®æ—¶è¿›åº¦: results/training_progress_realtime.png")
    print("  ğŸ“‰ å„æ¨¡å‹è®­ç»ƒæ›²çº¿: results/training_history_*.png")
    print("  ğŸ’¾ å„æ¨¡å‹æƒé‡: models/best_model_*.pth")
    print("\nä¸‹ä¸€æ­¥: è¿è¡Œ python evaluate.py è¯„ä¼°æ¨¡å‹æ€§èƒ½")